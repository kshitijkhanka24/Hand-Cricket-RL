
# ğŸ Hand Cricket AI â€” Q-Learning Powered Interactive Game

### **A Reinforcement Learning project where an AI learns to play Hand Cricket using Q-Learning.**

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.9+-blue?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Reinforcement%20Learning-Q--Learning-green?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Status-Active-success?style=for-the-badge"/>
</p>

---

## ğŸ“Œ Overview

This project implements an **Interactive Hand-Cricket game** where you can play against an AI agent trained using **Q-Learning**.
The system includes:

âœ” Human vs AI gameplay
âœ” Coin toss system
âœ” Multi-wicket (lives) cricket logic
âœ” Q-learningâ€“based batting & bowling agents
âœ” AI training from both simulated and real human play
âœ” Performance visualization using Matplotlib

The agent learns through repeated matches, updating its Q-table using the Bellman equation, eventually developing strategic batting or bowling behaviors.

---

## ğŸ® Game Modes

### **1ï¸âƒ£ Training Mode**

The AI trains for 100 simulated matches each for batting and bowling.
It adapts by learning against biased and random throw patterns.

### **2ï¸âƒ£ Interactive Play Mode**

You play a full 2-innings cricket match against the trained AI.

* Odd/Even coin toss
* Batting & bowling turns
* AI learns from your playing style after every match
* Match statistics and win rates displayed

---

## âœ¨ Features

### ğŸ§  Q-Learning AI

* Tabular Q-table
* Îµ-greedy exploration
* Last two human throws used as the game state
* Reward shaping for runs / outs
* Epsilon decay for stable learning

### ğŸ Cricket Mechanics

* Realistic hand-cricket rules
* Multi-wicket lives
* Score accumulation
* Matching numbers = OUT
* Chasing target in second innings

### ğŸ“Š Visualizations

* Training score progression
* Moving average graphs
* Summary statistics

---

## ğŸ”§ Tech Stack

* **Python 3.9+**
* **NumPy** (Q-table & math)
* **Matplotlib** (visualization)
* **Random** (opponent simulation)
* **Defaultdict** (Q-table storage)

---

## ğŸ—ï¸ Project Structure

```
ğŸ“ Hand-Cricket-Q-Learning
â”‚
â”œâ”€â”€ game.py                      # Full game + training loop
â”œâ”€â”€ HandCricketEnv               # Environment (runs, outs, wickets)
â”œâ”€â”€ QLearningAgent               # AI agent logic
â”œâ”€â”€ training_stats_plotter       # Matplotlib visualizer
â”‚
â””â”€â”€ README.md                    # You are here!
```

---

## ğŸš€ How It Works

### **ğŸŸ¥ 1. Environment (`HandCricketEnv`)**

Handles:

* Runs
* Wickets
* Outs
* Scoring rules
* Game-over status

Throws are compared every round:

```
if batting_throw == bowling_throw â†’ OUT  
else â†’ runs = abs(batting_throw - bowling_throw)
```

---

### **ğŸŸ¦ 2. State Representation**

The agent uses:

```
(last_throw_1, last_throw_2)
```

Keeps state small & efficient.

---

### **ğŸŸ© 3. Q-Learning Update Rule**

[
Q(s,a) â† Q(s,a) + Î± [ r + Î³ \max Q(s',a') - Q(s,a) ]
]

Rewards:

* Bowling AI â†’ Reward for OUT, penalty for runs
* Batting AI â†’ Reward for runs, penalty for out

---

### **ğŸŸ¨ 4. Action Selection (Îµ-Greedy)**

```
if random < Îµ:
    choose random move        # exploration
else:
    choose best Q-value move  # exploitation
```

Îµ decays every episode.

---

### **ğŸŸª 5. Training Loop**

âœ” 100 episodes of simulated human play
âœ” Biased/random human throws
âœ” Q-table updated every ball
âœ” Training summary printed every 20 episodes

---

## ğŸ“ˆ Training Visualization

After training, a 2-panel Matplotlib graph is generated:

* Episode vs Score
* Moving average
* Training summary box
* Final EPSILON value
* Q-Learning parameters


![Training Graph](./images/training.png)


---

## ğŸ® How to Play

### âœ” Step 1: Clone repo

```bash
git clone https://github.com/kshitijkhanka24/Hand-Cricket-RL
cd Hand-Cricket-RL
```

### âœ” Step 2: Install requirements

```bash
pip install numpy matplotlib
```

### âœ” Step 3: Run game

```bash
python game.py
```

### âœ” Step 4: Play a Match After Training

The program asks:

```
Want to play against the AI? (yes/no):
```

Then enjoy two full innings!

---

## ğŸ† Example Gameplay (Terminal)

![Gameplay](images/gameplay.png)

---

## ğŸ“š References

* GeeksforGeeks â€” Q-Learning (2025)
* freeCodeCamp â€” RL Tic-Tac-Toe Tutorial (2025)
* Wikipedia â€” Q-Learning (accessed 2025)
* Shubham Arya â€” Hand Cricket Game Explanation
* Autodesk Instructables â€” Hand Cricket Rules

---

## ğŸ’¡ Future Improvements

* Neural Network (Deep Q-Learning)
* Pattern-based opponent modeling
* GUI Version (Tkinter / Pygame)
* Multiplayer online mode
* Variable overs & cricket formats

---

## ğŸ¤ Contributing

Pull requests are welcome!
Open an issue to report bugs or propose ideas.

---

## â­ Show your support

If you found this project useful, please â­ star the repo!

---
